{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xek_hhHMDyoJ"
   },
   "source": [
    "#Installing packages & connecting drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ty1H-PrChAoV",
    "outputId": "429f9390-d488-4f1d-8810-c1327fa39dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8H-mGdfbadO",
    "outputId": "bacfbe5f-43ea-48db-db8d-a1d5c2480252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyedflib\n",
      "  Downloading pyEDFlib-0.1.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from pyedflib) (1.23.5)\n",
      "Installing collected packages: pyedflib\n",
      "Successfully installed pyedflib-0.1.30\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m803.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.12.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.10.7-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, PySocks, filelock, gdown\n",
      "Successfully installed PySocks-1.7.1 filelock-3.10.7 gdown-4.7.1 tqdm-4.65.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading...\n",
      "From: https://drive.google.com/uc?id=1jPkJSiTzxoo_Uxt_QLzgfvG48XWtIwEH&confirm=t\n",
      "To: /tf/artifacts_5s_128hz.pkl\n",
      " 61%|███████████████████████▎              | 3.43G/5.57G [01:47<02:11, 16.3MB/s]"
     ]
    }
   ],
   "source": [
    "!pip install  pyedflib\n",
    "!pip install einops\n",
    "!pip install gdown\n",
    "\n",
    "!gdown \"1jPkJSiTzxoo_Uxt_QLzgfvG48XWtIwEH&confirm=t\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "290lX9oPD4Pm"
   },
   "source": [
    "#Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mLwIIjN-h-kF"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = 'artifacts_5s_128hz.pkl'  # replace with your own file path\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sx29dGGKwcSY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import einops\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def to_pickle(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f'Pickled: {os.path.getsize(filename) / 1e6} MB / {os.path.getsize(filename) / 1e9} GB')\n",
    "\n",
    "def to_zip(pickle_filename, zip_filename):\n",
    "    with zipfile.ZipFile(zip_filename, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(pickle_filename)\n",
    "    print(f'Zipped: {os.path.getsize(zip_filename) / 1e6} MB / {os.path.getsize(zip_filename) / 1e9} GB')\n",
    "\n",
    "def from_zip(zip_filename):\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
    "        zipf.extractall()\n",
    "    print(f'Unzipped: {os.path.getsize(zip_filename) / 1e6} MB / {os.path.getsize(zip_filename) / 1e9} GB')\n",
    "        \n",
    "def from_pickle(pickle_filename):\n",
    "    with open(pickle_filename, 'rb') as f:\n",
    "        arr = pickle.load(f)\n",
    "        print(f'Loaded: {arr.shape}')\n",
    "        return arr\n",
    "\n",
    "def pickle_check(pickle_filename):\n",
    "    print('')\n",
    "    print('Checking pickle and zip functions...')\n",
    "    os.system(f'cp {pickle_filename} test.pkl')\n",
    "    data = from_pickle('test.pkl')\n",
    "    to_zip('test.pkl', 'test.zip')\n",
    "    from_zip('test.zip')\n",
    "    loaded_data = from_pickle('test.pkl')\n",
    "    assert np.array_equal(data, loaded_data)\n",
    "    os.remove('test.zip')\n",
    "    os.remove('test.pkl')\n",
    "    print('Success!\\n')\n",
    "\n",
    "def split_files(folder_path, num_subfolders):\n",
    "    # Get a list of all files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "    num_files = len(file_list)\n",
    "\n",
    "    # Calculate the number of files to put in each subfolder\n",
    "    files_per_subfolder = int(num_files / num_subfolders)\n",
    "    \n",
    "    # Create the subfolders if they don't already exist\n",
    "    subfolder_names = [f\"{folder_path}/{i}of{num_subfolders}\" for i in range(1, num_subfolders + 1)]\n",
    "    for subfolder_name in subfolder_names:\n",
    "        os.makedirs(subfolder_name, exist_ok=True)\n",
    "    \n",
    "    # Copy the files into the subfolders\n",
    "    progress_bar = tqdm(total=num_files)\n",
    "    subfolder_idx = 0\n",
    "    num_copied = 0\n",
    "    for file_name in file_list:\n",
    "        source_path = os.path.join(folder_path, file_name)\n",
    "        destination_folder = subfolder_names[subfolder_idx]\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.move(source_path, destination_path)\n",
    "        num_copied += 1\n",
    "        progress_bar.update(1)\n",
    "        if num_copied == files_per_subfolder:\n",
    "            num_files_in_subfolder = len(os.listdir(destination_folder))\n",
    "            print(f\"{destination_folder}: {num_files_in_subfolder}\")\n",
    "            if subfolder_idx < num_subfolders - 1:\n",
    "                subfolder_idx += 1\n",
    "                num_copied = 0\n",
    "    \n",
    "    progress_bar.close()\n",
    "\n",
    "def load_pickled_data(root_dir = 'data/training', file_name=None, folder_name='300'):\n",
    "    data = []\n",
    "    if file_name is None:\n",
    "        path = os.path.join(root_dir, f\"{folder_name}\")\n",
    "\n",
    "        if len(os.listdir(path)[0].split('_')) > 3:\n",
    "            frequency = int(os.listdir(path)[0].split('_')[2][:-2])\n",
    "        else:\n",
    "            frequency = 1\n",
    "\n",
    "        with open(os.path.join(path, file_name), \"rb\") as f:\n",
    "            data.append(pickle.load(f))\n",
    "    else:\n",
    "        if file_name.endswith(\".pkl\"):\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                data.append(pickle.load(f))\n",
    "        \n",
    "        if len(file_name.split('_')) > 3:\n",
    "            frequency = int(file_name.split('_')[2][:-2])\n",
    "        else:\n",
    "            frequency = 1\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    print('\\nLoading:\\n', data.shape, '\\n', 'Total hours:', round(data.shape[0] * data.shape[2] / 60 / 60 / frequency, 3), '\\n')\n",
    "    return data\n",
    "\n",
    "def save_to_pickle_multiple(data, num_files=10, target_path=\".\"):\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "\n",
    "    samples_per_file = data.shape[0] // num_files\n",
    "    remainder = data.shape[0] % num_files\n",
    "    for i in tqdm(range(num_files)):\n",
    "        start_idx = i * samples_per_file\n",
    "        end_idx = (i + 1) * samples_per_file\n",
    "        if i == num_files - 1:\n",
    "            end_idx = data.shape[0]\n",
    "        if i < remainder:\n",
    "            end_idx += 1\n",
    "        subset_data = data[start_idx:end_idx]\n",
    "        with open(os.path.join(target_path, f'data_{data.shape[2]}_1hz_{i+1}.pkl'), 'wb') as f:\n",
    "            pickle.dump(subset_data, f)\n",
    "def plot(data, save_name=None, show=False, annotate=False, artifact=None):\n",
    "        data = np.squeeze(data)\n",
    "\n",
    "        if annotate:\n",
    "            names = ['F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'FZ', 'CZ', 'PZ']\n",
    "\n",
    "            if artifact is not None:\n",
    "                # if artifact is a list \n",
    "                if isinstance(artifact, list):\n",
    "                    for i in artifact:\n",
    "                        names.append(i)\n",
    "                else:\n",
    "                    names = ['F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'FZ', 'CZ', 'PZ', artifact]\n",
    "\n",
    "            if data.shape[0] == len(names):\n",
    "                fig = plt.figure(figsize=(10,5), dpi=100)\n",
    "                for i in range(len(names)):\n",
    "                    plt.subplot(len(names), 1, i+1)\n",
    "                    plt.plot(data[i, :])\n",
    "                    if annotate:\n",
    "                        plt.annotate(names[i], xy=(1.05, 0.5), xycoords='axes fraction', horizontalalignment='right', verticalalignment='center')\n",
    "            elif data.shape[-1] == len(names):\n",
    "                fig = plt.figure(figsize=(10,5), dpi=100)\n",
    "                for i in range(len(names)):\n",
    "                    plt.subplot(len(names), 1, i+1)\n",
    "                    plt.plot(data[:, i])\n",
    "                    if annotate:\n",
    "                        plt.annotate(names[i], xy=(1.05, 0.5), xycoords='axes fraction', horizontalalignment='right', verticalalignment='center')\n",
    "\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(10,5), dpi=100)\n",
    "            for i in range(len(data)):\n",
    "                plt.subplot(len(data), 1, i+1)\n",
    "                plt.plot(data[i, :])\n",
    "                if annotate:\n",
    "                    plt.annotate(names[i], xy=(1.05, 0.5), xycoords='axes fraction', horizontalalignment='right', verticalalignment='center')\n",
    "\n",
    "\n",
    "        if save_name:\n",
    "            plt.savefig(save_name)\n",
    "        if show:\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "M_q-UWVywrRY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading:\n",
      " (51841, 21, 640) \n",
      " Total hours: 9216.178 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_pickled_data(root_dir = 'data/training', file_name= 'artifacts_5s_128hz.pkl', folder_name='300')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHOUodHWDNjG"
   },
   "source": [
    "#Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EqcWkBwj0851"
   },
   "outputs": [],
   "source": [
    "def preprocessing_transformer(dataset, batchsize, balance=False):\n",
    "    \n",
    "   # target is stored in last channel \n",
    "\n",
    "    # rearrange data so that the channels are in the last dimension (following convention)\n",
    "    dataset = einops.rearrange(dataset, 'b c t -> b t c')\n",
    "    x_data = dataset[:,:,:-2]\n",
    "    y_data_1 = dataset[:,:,-1] \n",
    "    y_data_2 = dataset[:,:,-2]  \n",
    "\n",
    "    if balance:\n",
    "\n",
    "        # if we want to reduce the dataset to only the samples that contain positive examples:\n",
    "        indices_1 = np.where(np.any(y_data_1 == 1, axis=1))[0]\n",
    "        indices_2  = np.where(np.any(y_data_2 == 1, axis=1))[0]\n",
    "        indices_comb = np.union1d(indices_1, indices_2)\n",
    "\n",
    "\n",
    "\n",
    "        # Extract the data and labels corresponding to these indices\n",
    "        reduced_data = x_data[indices_comb]\n",
    "        reduced_labels_1 = y_data_1[indices_comb]\n",
    "        reduced_labels_2 = y_data_2[indices_comb]  \n",
    "\n",
    "    # create a tensorflow dataset \n",
    "    ds = tf.data.Dataset.from_tensor_slices((reduced_data, reduced_labels_1, reduced_labels_2))\n",
    "    \n",
    "    ds = ds.map(lambda x,y1, y2: (x, tf.cast(y1, tf.int32), tf.cast(y2, tf.int32)))\n",
    "    ds = ds.shuffle(1000).batch(batchsize).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "   \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dZQ9BbPgwR-P"
   },
   "outputs": [],
   "source": [
    " def split(data, train=0.8, val=0.1, test=0.1):\n",
    "        \"\"\"\n",
    "        split the data into three sets namely training, validation and test\n",
    "        Args:\n",
    "            data: np.array\n",
    "            train: float\n",
    "            val: float\n",
    "            test: float\n",
    "        Returns: \n",
    "            A List of with the three datasets\n",
    "        \"\"\"\n",
    "\n",
    "        train_split_idx = int(data.shape[0]*0.8) # get index for split between train and val\n",
    "        val_split_idx = train_split_idx + int(data.shape[0]*0.1) # get index for split between val and test\n",
    "        train_ds = data[:train_split_idx, :, :] # split train\n",
    "        val_ds = data[train_split_idx:val_split_idx, :, :] # split val\n",
    "        test_ds = data[val_split_idx:, :, :] # split test\n",
    "        return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "U2MzCFT82a6_"
   },
   "outputs": [],
   "source": [
    "\n",
    "ds_train, ds_val, ds_test = split(dataset)\n",
    "\n",
    "ds_train_post = preprocessing_transformer(ds_train,\n",
    "                                    batchsize = 52, \n",
    "                                    balance = True)\n",
    "ds_val_post = preprocessing_transformer(ds_val,\n",
    "                                    batchsize = 52, \n",
    "                                    balance = True)\n",
    "ds_test_post = preprocessing_transformer(ds_test,\n",
    "                                    batchsize = 52, \n",
    "                                    balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pCeYGb4S3Ej5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 640, 19), dtype=tf.float64, name=None), TensorSpec(shape=(None, 640), dtype=tf.int32, name=None), TensorSpec(shape=(None, 640), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2LBKhPemwv1M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:04:47.555475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [11497,640]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-03-27 16:04:47.555822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [11497,640,19]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-03-27 16:04:47.746187: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-27 16:04:47.912653: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-27 16:04:48.200451: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ds_train_post.map(lambda x, y1, y2: (x, (y1, y2)))\n",
    "x_train, (y_train1, y_train2) = next(iter(train_dataset))\n",
    "\n",
    "val_dataset = ds_val_post.map(lambda x, y1, y2: (x, (y1, y2)))\n",
    "x_val, (y_val1, y_val2) = next(iter(train_dataset))\n",
    "\n",
    "test_dataset = ds_test_post.map(lambda x, y1, y2: (x, (y1, y2)))\n",
    "x_val, (y_val1, y_val2) = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61bs0SqNDKXP"
   },
   "source": [
    "##Counting Balance of Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Y5XeKQGjpj50"
   },
   "outputs": [],
   "source": [
    "# How imbalanced is this dataset?\n",
    "dataset = einops.rearrange(dataset, 'b c t -> b t c')\n",
    "x_data = dataset[:,:,:-2]\n",
    "y_data_1 = dataset[:,:,-1] \n",
    "y_data_2 = dataset[:,:,-2]  \n",
    "\n",
    "# if we want to reduce the dataset to only the samples that contain positive examples:\n",
    "indices_1 = np.where(np.any(y_data_1 == 1, axis=1))[0]\n",
    "indices_2  = np.where(np.any(y_data_2 == 1, axis=1))[0]\n",
    "indices_comb = np.union1d(indices_1, indices_2)\n",
    "\n",
    "# Extract the data and labels corresponding to these indices\n",
    "reduced_data = x_data[indices_comb]\n",
    "reduced_labels_1 = y_data_1[indices_comb]\n",
    "reduced_labels_2 = y_data_2[indices_comb]  \n",
    "\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "# Iterate over the dataset and count the number of 1s and 0s\n",
    "for target_seq in reduced_labels:\n",
    "    \n",
    "    count_0 += tf.math.count_nonzero(target_seq == 0)\n",
    "    count_1 += tf.math.count_nonzero(target_seq == 1)\n",
    "\n",
    "# Compute the fraction of 1s in the dataset\n",
    "fraction_1 = count_1 / (count_0 + count_1)\n",
    "print(count_0)\n",
    "# Print the fraction of 1s in the dataset\n",
    "print(f\"Fraction of 1s in the dataset: {fraction_1:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# This dataset is crazy imbalanced! only 4% of labels are positive\n",
    "\n",
    "# for artefacts 300s_100Hz its 13%\n",
    "# for artefacts 300s_128Hz its 14%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOFrgPKEEzv1"
   },
   "source": [
    "#Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQEiuybm3mez"
   },
   "source": [
    "##The Baseline Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oEGynoNF3TJC"
   },
   "outputs": [],
   "source": [
    "class TestModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_units, num_layers, num_heads, num_conv_layers, aggregation_mode):\n",
    "\n",
    "    super(TestModel, self).__init__()\n",
    "    \n",
    "    self.aggregation_mode = aggregation_mode\n",
    "    self.conv_block = []\n",
    "    \n",
    "    for i in range(num_conv_layers):\n",
    "        \n",
    "        self.conv_block.append(tf.keras.layers.Conv1D(8*i + 8, 3, activation='relu'))\n",
    "        # max pooling throws an error!\n",
    "        #self.conv_block.append(tf.keras.layers.MaxPooling2D(2))\n",
    "        \n",
    "    self.dense_layers =[]\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "            self.dense_layers.append(tf.keras.layers.Dense(num_units, activation='relu'))\n",
    "    \n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(num_heads, 640)\n",
    "    self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "    self.dense = tf.keras.layers.Dense(640, activation = \"sigmoid\")\n",
    "    self.dense2 = tf.keras.layers.Dense(640, activation = \"sigmoid\")\n",
    "    \n",
    "\n",
    "  def call(self, x):\n",
    "    \n",
    "    for layer in self.conv_block:\n",
    "        x = layer(x)\n",
    "                \n",
    "    x = self.mha(x, x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    for layer in self.dense_layers:\n",
    "        x = layer(x)\n",
    "        \n",
    "    output_eye = self.dense(x)\n",
    "    output_muscle = self.dense2(x)\n",
    "\n",
    "    if self.aggregation_mode == 1:\n",
    "    # assuming that an artifact occurring in any pair of channels are independent events, the\n",
    "    # probability of it occurring in any one is:\n",
    "\n",
    "        output_eye =  1-tf.math.reduce_prod(output_eye, axis=1)\n",
    "        output_muscle = 1- tf.math.reduce_prod(output_muscle, axis=1)\n",
    "    \n",
    "    else: \n",
    "        output_eye = tf.math.reduce_mean(output_eye, axis=1)\n",
    "        output_muscle = tf.math.reduce_mean(output_muscle, axis=1)\n",
    "\n",
    "    return output_eye, output_muscle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaIYverCCrSW"
   },
   "source": [
    "## Transformer Convolutional NN (Peh et al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JdcavzZENfs4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (32, 250,19)\n",
    "# Define the CNN architecture\n",
    "cnn = tf.keras.Sequential([\n",
    "    # Convolutional layer 1 with 8 filters, filter size 3, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(8, 3, activation='relu', input_shape=input_shape),\n",
    "    # Max-pooling with stride 2\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    # Convolutional layer 2 with 16 filters, filter size 3, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    # Max-pooling with stride 2\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    # Convolutional layer 3 with 32 filters, filter size 3, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding = 'same'),\n",
    "    # Max-pooling with stride 2\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    # Convolutional layer 4 with 64 filters, filter size 3, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu', padding = 'same'),\n",
    "    # Max-pooling with stride 2\n",
    "    tf.keras.layers.MaxPooling2D(2),\n",
    "    # Convolutional layer 5 with 128 filters, filter size 3, and ReLU activation\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu', padding = 'same'),\n",
    "    # Max-pooling with stride 2\n",
    "    #tf.keras.layers.MaxPooling2D(2)\n",
    "])\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class Transformer_encoder(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Transformer_encoder, self).__init__()\n",
    "    self.flatten = tf.keras.layers.Flatten(),\n",
    "    # Add a dense layer for query, key, and value\n",
    "    self.dense = tf.keras.layers.Dense(256, activation='relu'),\n",
    "    # Use the Multi-Head Attention layer for the transformer\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim = 250),\n",
    "    # Add a dense layer for the feed-forward network\n",
    "    self.dense2 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "\n",
    "  def call(self, input):\n",
    "    x = self.flatten(input)\n",
    "    \n",
    "    #print(input)\n",
    "    #print(type(x))\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    #print(x)\n",
    "    #x = self.dense(x)\n",
    "    x = self.mha(x,x)\n",
    "    x = self.dense2(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "transformer_encoder = Transformer_encoder()\n",
    "# Combine the CNN and Transformer encoder\n",
    "\n",
    "#cnn(tf.keras.Input(shape = (32, 250,19)))\n",
    "cnn(tf.keras.Input(shape = (32, 250,19)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js2jyiWZC-sJ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWuJeYHSC4JS"
   },
   "source": [
    "##Special Callback to see Outputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UTsO0SIuiudB"
   },
   "outputs": [],
   "source": [
    "class PrintOutputsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, test_dataset):\n",
    "        super(PrintOutputsCallback, self).__init__()\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      \n",
    "        # Get a batch of test data\n",
    "        x, y_true = next(iter(self.test_dataset))\n",
    "        \n",
    "        # Predict the outputs for this batch\n",
    "        y_pred = self.model.predict(x)\n",
    "        \n",
    "        # Print some outputs and targets\n",
    "        print(f\"Outputs: {y_pred[:3]}\")\n",
    "        print(f\"Targets: {y_true[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7LP9RNXZe6vW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('checkpoint_dir'):\n",
    "    os.makedirs('checkpoint_dir')\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='checkpoint_dir/model_{epoch:02d}.h5',\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSmpR4KLE8nl"
   },
   "source": [
    "## Normal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "N_FqNAPmtyRM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 16s 59ms/step - loss: 1.2326 - output_1_loss: 0.5821 - output_2_loss: 0.6505 - output_1_precision_1: 0.3564 - output_1_binary_accuracy: 0.7038 - output_2_precision_1: 0.5923 - output_2_binary_accuracy: 0.6271 - val_loss: 1.1757 - val_output_1_loss: 0.5757 - val_output_2_loss: 0.6000 - val_output_1_precision_1: 0.3860 - val_output_1_binary_accuracy: 0.6999 - val_output_2_precision_1: 0.9446 - val_output_2_binary_accuracy: 0.7280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b174cfe50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "hparams = {\n",
    "        HP_NUM_UNITS: 640,\n",
    "        HP_NUM_LAYERS: 1,\n",
    "        HP_NUM_HEADS: 4,\n",
    "        HP_NUM_CONVLAYERS: 0,\n",
    "        HP_AGGREGATION: 0\n",
    "                }\n",
    "\n",
    "model = TestModel(TestModel(hparams[HP_NUM_UNITS], hparams[HP_NUM_LAYERS], hparams[HP_NUM_HEADS], hparams[HP_NUM_CONVLAYERS], hparams[HP_AGGREGATION])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "              optimizer=tf.keras.optimizers.Adam(), \n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "#model.predict(ds_train_post.take(1))\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data = val_dataset, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrzTDHFlECLD"
   },
   "source": [
    "##Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Gy5N0h1EdsU"
   },
   "source": [
    "### Set up grid and model for gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zo9zan1KEETu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import time\n",
    "\n",
    "# Define the hyperparameters you want to tune\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([256, 640]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2,3,4]))\n",
    "HP_NUM_HEADS = hp.HParam('num_heads', hp.Discrete([4,8]))\n",
    "HP_NUM_CONVLAYERS = hp.HParam('num_convlayers', hp.Discrete([1,2,3,4]))\n",
    "\n",
    "#can probably take this out since 1 seems markedly worse than 0 after 1 epoche\n",
    "HP_AGGREGATION = hp.HParam('aggregation', hp.Discrete([0,1]))\n",
    "\n",
    "# Define the metrics you want to record\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Define a function to build your model\n",
    "\n",
    "def create_model(hparams):\n",
    "\n",
    "    model = TestModel(hparams[HP_NUM_UNITS], hparams[HP_NUM_LAYERS], hparams[HP_NUM_HEADS], hparams[HP_NUM_CONVLAYERS], hparams[HP_AGGREGATION])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define a function to run a single experiment\n",
    "\n",
    "def run_experiment(hparams, epochs, logdir, savedir, checkpointdir):\n",
    "    \n",
    "    model = create_model(hparams)\n",
    "   \n",
    " \n",
    "    \n",
    "\n",
    "    # Create the model using the hyperparameters\n",
    "    # Compile the model\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "              optimizer=tf.keras.optimizers.Adam(), \n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "        # Train the model\n",
    "\n",
    "    model.fit(train_dataset, \n",
    "              epochs=epochs, \n",
    "              validation_data = val_dataset,\n",
    "              callbacks=[tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "                        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "                        tf.keras.callbacks.ModelCheckpoint(filepath= os.path.join(checkpointdir, \"ckpt_{epoch}\") ,monitor='val_loss',save_weights_only=True), # save checkpoints when val loss goes down\n",
    "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)], # early stopping in the case that loss doesnt go down for 3 epochs\n",
    "              ) \n",
    "\n",
    "    \n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = model.evaluate(test_dataset)\n",
    "    model.save(savedir)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qN7VUMhHEZio"
   },
   "source": [
    "### Search the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bRPGR7gbEVUg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 1, 'aggregation': 0}\n",
      "222/222 [==============================] - 16s 54ms/step - loss: 1.2519 - output_1_loss: 0.5851 - output_2_loss: 0.6668 - output_1_precision_7: 0.3253 - output_1_binary_accuracy: 0.7114 - output_2_precision_7: 0.5449 - output_2_binary_accuracy: 0.6035 - val_loss: 1.2050 - val_output_1_loss: 0.5733 - val_output_2_loss: 0.6317 - val_output_1_precision_7: 0.3891 - val_output_1_binary_accuracy: 0.7001 - val_output_2_precision_7: 0.9809 - val_output_2_binary_accuracy: 0.6599\n",
      "26/26 [==============================] - 1s 24ms/step - loss: 1.1971 - output_1_loss: 0.5562 - output_2_loss: 0.6408 - output_1_precision_7: 0.5556 - output_1_binary_accuracy: 0.7412 - output_2_precision_7: 0.6367 - output_2_binary_accuracy: 0.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:43:28.094529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.103806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.109125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.114250: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.434172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.453497: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.474563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:28.523741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 1, 'aggregation': 1}\n",
      "222/222 [==============================] - 16s 60ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_8: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_8: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_8: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_8: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_8: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_8: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:43:46.572008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.581303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.586870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.592155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.923422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.943902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:46.965211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:43:47.012000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-2\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 2, 'aggregation': 0}\n",
      "222/222 [==============================] - 16s 48ms/step - loss: 1.2347 - output_1_loss: 0.5851 - output_2_loss: 0.6496 - output_1_precision_9: 0.3195 - output_1_binary_accuracy: 0.7125 - output_2_precision_9: 0.6090 - output_2_binary_accuracy: 0.6340 - val_loss: 1.1888 - val_output_1_loss: 0.5752 - val_output_2_loss: 0.6136 - val_output_1_precision_9: 0.0000e+00 - val_output_1_binary_accuracy: 0.7054 - val_output_2_precision_9: 0.9885 - val_output_2_binary_accuracy: 0.7126\n",
      "26/26 [==============================] - 1s 18ms/step - loss: 1.2352 - output_1_loss: 0.5812 - output_2_loss: 0.6541 - output_1_precision_9: 0.0000e+00 - output_1_binary_accuracy: 0.7352 - output_2_precision_9: 0.7407 - output_2_binary_accuracy: 0.6269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:44:04.247975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.256892: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.262036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.268262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.598578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.618677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.639897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:04.698686: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-3\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 2, 'aggregation': 1}\n",
      "222/222 [==============================] - 15s 56ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_10: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_10: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_10: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_10: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 18ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_10: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_10: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:44:21.708436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:21.717634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:21.722956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:21.728098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:22.061630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:22.081506: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:22.102734: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:22.162101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-4\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 3, 'aggregation': 0}\n",
      "222/222 [==============================] - 17s 62ms/step - loss: 1.2422 - output_1_loss: 0.5852 - output_2_loss: 0.6570 - output_1_precision_11: 0.3406 - output_1_binary_accuracy: 0.7092 - output_2_precision_11: 0.5945 - output_2_binary_accuracy: 0.6256 - val_loss: 1.1990 - val_output_1_loss: 0.5676 - val_output_2_loss: 0.6314 - val_output_1_precision_11: 0.3333 - val_output_1_binary_accuracy: 0.7054 - val_output_2_precision_11: 0.9716 - val_output_2_binary_accuracy: 0.6740\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 1.1969 - output_1_loss: 0.5523 - output_2_loss: 0.6446 - output_1_precision_11: 0.4000 - output_1_binary_accuracy: 0.7352 - output_2_precision_11: 0.7375 - output_2_binary_accuracy: 0.6234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:44:41.032934: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.041696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.046918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.052079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.400004: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.420029: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.441169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:44:41.515267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, query_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-5\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 3, 'aggregation': 1}\n",
      "222/222 [==============================] - 17s 60ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_12: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_12: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_12: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_12: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 23ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_12: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_12: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:45:00.056315: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.065519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.070829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.076013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.433864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.462332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.536000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:00.657791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,634,24]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, query_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-6\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 4, 'aggregation': 0}\n",
      "222/222 [==============================] - 14s 43ms/step - loss: 1.2236 - output_1_loss: 0.5761 - output_2_loss: 0.6475 - output_1_precision_13: 0.4112 - output_1_binary_accuracy: 0.7076 - output_2_precision_13: 0.5923 - output_2_binary_accuracy: 0.6311 - val_loss: 1.1569 - val_output_1_loss: 0.5607 - val_output_2_loss: 0.5962 - val_output_1_precision_13: 0.4456 - val_output_1_binary_accuracy: 0.6996 - val_output_2_precision_13: 0.8955 - val_output_2_binary_accuracy: 0.7353\n",
      "26/26 [==============================] - 1s 29ms/step - loss: 1.1143 - output_1_loss: 0.5142 - output_2_loss: 0.6001 - output_1_precision_13: 0.5629 - output_1_binary_accuracy: 0.7477 - output_2_precision_13: 0.7216 - output_2_binary_accuracy: 0.6688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:45:17.765808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:17.833758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:17.838803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:17.844874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:18.229430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:18.248733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:18.269781: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:18.367953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-7\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 4, 'num_convlayers': 4, 'aggregation': 1}\n",
      "222/222 [==============================] - 15s 48ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_14: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_14: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_14: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_14: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 18ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_14: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_14: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:45:34.824309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:34.833178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:34.838221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:34.843368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:35.227438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:35.247087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:35.269414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:45:35.358472: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,632,32]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-8\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 8, 'num_convlayers': 1, 'aggregation': 0}\n",
      "222/222 [==============================] - 25s 101ms/step - loss: 1.2080 - output_1_loss: 0.5718 - output_2_loss: 0.6362 - output_1_precision_15: 0.4517 - output_1_binary_accuracy: 0.7131 - output_2_precision_15: 0.6176 - output_2_binary_accuracy: 0.6467 - val_loss: 1.1393 - val_output_1_loss: 0.5737 - val_output_2_loss: 0.5656 - val_output_1_precision_15: 0.4713 - val_output_1_binary_accuracy: 0.7034 - val_output_2_precision_15: 0.8588 - val_output_2_binary_accuracy: 0.7412\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.2777 - output_1_loss: 0.6254 - output_2_loss: 0.6523 - output_1_precision_15: 0.5413 - output_1_binary_accuracy: 0.7409 - output_2_precision_15: 0.6910 - output_2_binary_accuracy: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:46:02.792080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:02.800949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:02.806958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:02.812325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:03.120351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:03.140836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:03.162978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:03.208693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-9\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 8, 'num_convlayers': 1, 'aggregation': 1}\n",
      "222/222 [==============================] - 26s 103ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_16: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_16: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_16: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_16: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_16: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_16: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:46:30.849972: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:30.858750: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:30.864112: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:30.869190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:31.181839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:31.203230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:31.224930: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:31.271116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,638,8]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-10\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 8, 'num_convlayers': 2, 'aggregation': 0}\n",
      "222/222 [==============================] - 20s 78ms/step - loss: 1.2296 - output_1_loss: 0.5855 - output_2_loss: 0.6441 - output_1_precision_17: 0.3368 - output_1_binary_accuracy: 0.7090 - output_2_precision_17: 0.6164 - output_2_binary_accuracy: 0.6424 - val_loss: 1.1086 - val_output_1_loss: 0.5629 - val_output_2_loss: 0.5457 - val_output_1_precision_17: 0.0000e+00 - val_output_1_binary_accuracy: 0.7054 - val_output_2_precision_17: 0.8104 - val_output_2_binary_accuracy: 0.7310\n",
      "26/26 [==============================] - 1s 28ms/step - loss: 1.1847 - output_1_loss: 0.5741 - output_2_loss: 0.6106 - output_1_precision_17: 0.0000e+00 - output_1_binary_accuracy: 0.7352 - output_2_precision_17: 0.7484 - output_2_binary_accuracy: 0.7177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:46:53.168123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.176736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.181926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.187007: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.514227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.534167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.556138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-27 16:46:53.616097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,636,16]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, query_layer_call_fn, query_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-11\n",
      "{'num_units': 256, 'num_layers': 1, 'num_heads': 8, 'num_convlayers': 2, 'aggregation': 1}\n",
      "222/222 [==============================] - 22s 83ms/step - loss: 19.7105 - output_1_loss: 10.9241 - output_2_loss: 8.7863 - output_1_precision_18: 0.2836 - output_1_binary_accuracy: 0.2836 - output_2_precision_18: 0.4238 - output_2_binary_accuracy: 0.4238 - val_loss: 20.0898 - val_output_1_loss: 10.7563 - val_output_2_loss: 9.3336 - val_output_1_precision_18: 0.2946 - val_output_1_binary_accuracy: 0.2946 - val_output_2_precision_18: 0.3879 - val_output_2_binary_accuracy: 0.3879\n",
      "26/26 [==============================] - 1s 31ms/step - loss: 20.6758 - output_1_loss: 11.2120 - output_2_loss: 9.4639 - output_1_precision_18: 0.2648 - output_1_binary_accuracy: 0.2648 - output_2_precision_18: 0.3794 - output_2_binary_accuracy: 0.3794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m({h\u001b[38;5;241m.\u001b[39mname: hparams[h] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hparams})\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Run a single experiment\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/hparam_tuning/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/models/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpointdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs/checkpoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Record the results in TensorBoard\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#with tf.summary.create_file_writer('logs/hparam_tuning/' + str(session_num)).as_default():\u001b[39;00m\n\u001b[1;32m     33\u001b[0m  \u001b[38;5;66;03m#   hp.hparams_config(\u001b[39;00m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;66;03m#      hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\u001b[39;00m\n\u001b[1;32m     35\u001b[0m    \u001b[38;5;66;03m##     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\u001b[39;00m\n\u001b[1;32m     36\u001b[0m      \u001b[38;5;66;03m#   )\u001b[39;00m\n\u001b[1;32m     37\u001b[0m session_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[57], line 53\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(hparams, epochs, logdir, savedir, checkpointdir)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     52\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2826\u001b[0m, in \u001b[0;36mModel.save\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m   2773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves a model as a TensorFlow SavedModel or HDF5 file.\u001b[39;00m\n\u001b[1;32m   2775\u001b[0m \n\u001b[1;32m   2776\u001b[0m \u001b[38;5;124;03m    See the [Serialization and Saving guide](\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2824\u001b[0m \u001b[38;5;124;03m    Note that `model.save()` is an alias for `tf.keras.models.save_model()`.\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2826\u001b[0m     \u001b[43msaving_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/saving_api.py:145\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/save.py:168\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mSharedObjectSavingScope():\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m keras_option_scope(\n\u001b[1;32m    166\u001b[0m         save_traces\u001b[38;5;241m=\u001b[39msave_traces, in_tf_saved_model_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     ):\n\u001b[0;32m--> 168\u001b[0m         \u001b[43msaved_model_save\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save.py:98\u001b[0m, in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mdeprecated_internal_learning_phase_scope(\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mkeras_option_scope(save_traces):\n\u001b[0;32m---> 98\u001b[0m         saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m \u001b[43msave_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Save all metadata to a separate file in the SavedModel directory.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m generate_keras_metadata(saved_nodes, node_paths)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py:1276\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1272\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1273\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1275\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1277\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1278\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py:1455\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py:1398\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1396\u001b[0m augmented_graph_view \u001b[38;5;241m=\u001b[39m _AugmentedGraphView(obj)\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1398\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m \u001b[43msignature_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_function_to_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m      \u001b[49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1401\u001b[0m signatures, wrapped_functions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1402\u001b[0m     signature_serialization\u001b[38;5;241m.\u001b[39mcanonicalize_signatures(signatures))\n\u001b[1;32m   1403\u001b[0m signature_serialization\u001b[38;5;241m.\u001b[39mvalidate_augmented_graph_view(augmented_graph_view)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/signature_serialization.py:103\u001b[0m, in \u001b[0;36mfind_function_to_export\u001b[0;34m(saveable_view)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m possible_signatures \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, (def_function\u001b[38;5;241m.\u001b[39mFunction, defun\u001b[38;5;241m.\u001b[39mConcreteFunction)):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/save.py:180\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache:\n\u001b[1;32m    178\u001b[0m   children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache[obj] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 180\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaveType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[1;32m    185\u001b[0m       child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m children \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     77\u001b[0m   children\u001b[38;5;241m.\u001b[39mappend(base\u001b[38;5;241m.\u001b[39mTrackableReference(name, ref))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/trackable_view.py:84\u001b[0m, in \u001b[0;36mTrackableView.children\u001b[0;34m(cls, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m obj\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n\u001b[1;32m     83\u001b[0m children \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trackable_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     85\u001b[0m   ref \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert_to_trackable(ref, parent\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m     86\u001b[0m   children[name] \u001b[38;5;241m=\u001b[39m ref\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:3733\u001b[0m, in \u001b[0;36mModel._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   3730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_tf_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3733\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trackable_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavedmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m train_function\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py:3466\u001b[0m, in \u001b[0;36mLayer._trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   3462\u001b[0m     cache \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3463\u001b[0m     \u001b[38;5;66;03m# TODO(b/213628533): This must be called before super() to ensure\u001b[39;00m\n\u001b[1;32m   3464\u001b[0m     \u001b[38;5;66;03m# that any input shape changes are applied before getting the config\u001b[39;00m\n\u001b[1;32m   3465\u001b[0m     \u001b[38;5;66;03m# of the model.\u001b[39;00m\n\u001b[0;32m-> 3466\u001b[0m     children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trackable_saved_model_saver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrackable_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3470\u001b[0m     children \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/base_serialization.py:61\u001b[0m, in \u001b[0;36mSavedModelSaver.trackable_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mshould_save_traces():\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m---> 61\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects_to_serialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialization_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m children\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions_to_serialize(serialization_cache))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:79\u001b[0m, in \u001b[0;36mLayerSavedModelSaver.objects_to_serialize\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjects_to_serialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, serialization_cache):\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_serialized_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialization_cache\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mobjects_to_serialize\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:106\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    101\u001b[0m     save_impl\u001b[38;5;241m.\u001b[39mshould_skip_serialization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_must_restore_from_config\n\u001b[1;32m    103\u001b[0m ):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m serialized_attr\n\u001b[0;32m--> 106\u001b[0m object_dict, function_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_serialized_attributes_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialization_cache\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_objects(object_dict)\n\u001b[1;32m    111\u001b[0m serialized_attr\u001b[38;5;241m.\u001b[39mset_and_validate_functions(function_dict)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/model_serialization.py:57\u001b[0m, in \u001b[0;36mModelSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_signature \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mdefault_save_signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Other than the default signature function, all other attributes match\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# with the ones serialized by Layer.\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m objects, functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_serialized_attributes_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialization_cache\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m default_signature\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objects, functions\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:117\u001b[0m, in \u001b[0;36mLayerSavedModelSaver._get_serialized_attributes_internal\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns dictionary of serialized attributes.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m objects \u001b[38;5;241m=\u001b[39m save_impl\u001b[38;5;241m.\u001b[39mwrap_layer_objects(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, serialization_cache)\n\u001b[0;32m--> 117\u001b[0m functions \u001b[38;5;241m=\u001b[39m \u001b[43msave_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_layer_functions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialization_cache\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Attribute validator requires that the default save signature is added\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# to function dict, even if the value is None.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m functions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_default_save_signature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:223\u001b[0m, in \u001b[0;36mwrap_layer_functions\u001b[0;34m(layer, serialization_cache)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m fns\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fn, LayerCall):\n\u001b[0;32m--> 223\u001b[0m                 fn\u001b[38;5;241m.\u001b[39mget_concrete_function()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Restore overwritten functions and losses\u001b[39;00m\n\u001b[1;32m    226\u001b[0m _restore_child_layer_functions(original_fns)\n",
      "File \u001b[0;32m/usr/lib/python3.8/contextlib.py:120\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:390\u001b[0m, in \u001b[0;36mtracing_scope\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mdeprecated_internal_learning_phase_scope(training):\n\u001b[0;32m--> 390\u001b[0m         \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1258\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1257\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1258\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1249\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m   \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m   \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m-> 1249\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   1250\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1253\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:667\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    664\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 667\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:632\u001b[0m, in \u001b[0;36mlayer_call_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m    623\u001b[0m     layer,\n\u001b[1;32m    624\u001b[0m     inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    628\u001b[0m ):\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    630\u001b[0m         layer\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    631\u001b[0m     ):\n\u001b[0;32m--> 632\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m _restore_layer_losses(original_losses)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:553\u001b[0m, in \u001b[0;36mLayerCallCollection._maybe_wrap_with_training_arg.<locals>.wrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    545\u001b[0m     (args, kwargs,) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_spec\u001b[38;5;241m.\u001b[39mset_arg_value(\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m         pop_kwarg_if_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    552\u001b[0m     )\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:718\u001b[0m, in \u001b[0;36m_extract_outputs_from_fn.<locals>.call\u001b[0;34m(inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_and_return_conditional_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/saved_model/save_impl.py:672\u001b[0m, in \u001b[0;36mLayerCall.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_trace(args, kwargs)\n\u001b[0;32m--> 672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1771\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1768\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_override_gradient_function(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m       {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function(),\n\u001b[1;32m   1770\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatefulPartitionedCall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gradient_function()}):\n\u001b[0;32m-> 1771\u001b[0m     flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mforward_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_tangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m forward_backward\u001b[38;5;241m.\u001b[39mrecord(flat_outputs)\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:409\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_control_captures):\n\u001b[1;32m    403\u001b[0m       \u001b[38;5;66;03m# The caller must use record_operation to record this operation in the\u001b[39;00m\n\u001b[1;32m    404\u001b[0m       \u001b[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001b[39;00m\n\u001b[1;32m    405\u001b[0m       \u001b[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001b[39;00m\n\u001b[1;32m    406\u001b[0m       \u001b[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001b[39;00m\n\u001b[1;32m    407\u001b[0m       \u001b[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001b[39;00m\n\u001b[1;32m    408\u001b[0m       \u001b[38;5;28;01mwith\u001b[39;00m tape\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m--> 409\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitioned_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, func_graph_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_graph_outputs):\n\u001b[1;32m    418\u001b[0m   handle_data_util\u001b[38;5;241m.\u001b[39mcopy_handle_data(func_graph_output, outputs[i])\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/functional_ops.py:1222\u001b[0m, in \u001b[0;36mpartitioned_call\u001b[0;34m(args, f, tout, executing_eagerly, config, executor_type)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_compile_attr \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdefinition\u001b[38;5;241m.\u001b[39mattr:\n\u001b[1;32m   1221\u001b[0m   op_attrs[xla_compile_attr] \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdefinition\u001b[38;5;241m.\u001b[39mattr[xla_compile_attr]\n\u001b[0;32m-> 1222\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:576\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    569\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    570\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    571\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    574\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    575\u001b[0m           instructions)\n\u001b[0;32m--> 576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:3752\u001b[0m, in \u001b[0;36mGraph.create_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3750\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, Tensor):\n\u001b[1;32m   3751\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput #\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is not a tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (idx, a))\n\u001b[0;32m-> 3752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3753\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py:707\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    705\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    706\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:3814\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3814\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3815\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3816\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3817\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3818\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3819\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3820\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3821\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3822\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3823\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:2112\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2109\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 2112\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_c_op(c_op\u001b[38;5;241m=\u001b[39mc_op, g\u001b[38;5;241m=\u001b[39mg)\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1970\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1966\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[1;32m   1967\u001b[0m                                          serialized)\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1970\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1972\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter search space\n",
    "\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "session_num = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "       for num_heads in HP_NUM_HEADS.domain.values:\n",
    "         for num_convlayers in HP_NUM_CONVLAYERS.domain.values:\n",
    "            for aggregation in HP_AGGREGATION.domain.values:\n",
    "                hparams = {\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_NUM_LAYERS: num_layers,\n",
    "                    HP_NUM_HEADS: num_heads,\n",
    "                    HP_NUM_CONVLAYERS: num_convlayers,\n",
    "                    HP_AGGREGATION: aggregation\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "\n",
    "                # Run a single experiment\n",
    "                accuracy = run_experiment(\n",
    "                    hparams=hparams,\n",
    "                    epochs = 1,\n",
    "                    logdir='logs/hparam_tuning/' + run_name, \n",
    "                    savedir='logs/models/'+run_name, \n",
    "                    checkpointdir='logs/checkpoints'+run_name)\n",
    "\n",
    "                # Record the results in TensorBoard\n",
    "                #with tf.summary.create_file_writer('logs/hparam_tuning/' + str(session_num)).as_default():\n",
    "                 #   hp.hparams_config(\n",
    "                  #      hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "                   ##     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "                     #   )\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLUJX-5OFrEw"
   },
   "source": [
    "## Visualisation & Upload of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mDfAqIcQFqZD"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QfqhcM-8FvLQ"
   },
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DB2flJjkF1Ha"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev upload \\\n",
    "  --logdir /content/logs/hparam_tuning \\\n",
    "  --name \"Artifact Detection 6\" \\\n",
    "  --description \"Second Try Hyperparameter Optimization with models as hyperparameter - model cannot be selected in hparams\" \\\n",
    "  --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvCEWvzdDFF3"
   },
   "source": [
    "# Random Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8NuZfUGSeCsC"
   },
   "outputs": [],
   "source": [
    "                            \n",
    "x_example = x_data[0:1]\n",
    "y_example = y_data[0:1]\n",
    "\n",
    "# Get the model's prediction\n",
    "y_pred = model.predict(x_example)\n",
    "\n",
    "# Calculate the binary cross-entropy loss for the example\n",
    "loss_fn = weighted_binary_crossentropy(50,1)\n",
    "loss_example = tf.reduce_mean(loss_fn(y_example, y_pred))\n",
    "\n",
    "# Print the output, target values, and loss for the example\n",
    "print(\"Model Input:\\n\", x_example)\n",
    "print(\"Model Output:\\n\", y_pred)\n",
    "print(\"\\nTarget Values:\\n\", y_example)\n",
    "print(\"\\nBinary Cross-Entropy Loss for the Example:\\n\", loss_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PhyIQxch1d77"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a sample tensor of shape (9, 640)\n",
    "tensor = tf.random.uniform((42, 640))\n",
    "\n",
    "# Perform the operation: 1 - (1 - p1) * (1 - p2) * ...\n",
    "result = 1 - tf.reduce_prod(1 - tensor, axis=0)\n",
    "\n",
    "# Check the shape of the result tensor\n",
    "print(\"Result tensor shape:\", result.shape)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "KaIYverCCrSW"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
