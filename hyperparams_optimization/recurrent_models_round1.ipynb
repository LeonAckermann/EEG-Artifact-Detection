{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from mylibs import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xhU8Cskx6dTw"
   },
   "source": [
    "## Data\n",
    "Load, split and prepare the data. Documentation of the functions can be found in data/data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data.data import Data\n",
    "handler = Data()\n",
    "data = handler.load('../artifacts_5s_128hz.pkl')\n",
    "train_split, val_split, test_split = handler.split(data)\n",
    "train = handler.prepare_data(train_split, balance=True, dataset=True)\n",
    "val = handler.prepare_data(val_split, dataset=True)\n",
    "test_features, test_labels = handler.prepare_data(test_split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all other metrics that we would like to track for each model architecture\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      keras.metrics.CategoricalCrossentropy(name='loss'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T5qFDNtvjZ9m"
   },
   "source": [
    "## Dynamic model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oTmSYVtj2RHP"
   },
   "outputs": [],
   "source": [
    "from architectures.MultiLayerLSTM import MultiLayerLSTM\n",
    "from architectures.BidirectionalLSTM import BidirectionalLSTM\n",
    "\n",
    "def build_model(hparams):\n",
    "    \"\"\"\n",
    "    returns a model based on the selected hyperparameters\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"MultiLayerLSTM\": MultiLayerLSTM(num_hidden_units = hparams['HP_NUM_HIDDEN_UNITS'], \n",
    "                                        num_lstm_layers=hparams['HP_NUM_LSTM_LAYERS'],\n",
    "                                        num_dense_units = hparams['HP_NUM_DENSE_LAYERS'],\n",
    "                                        num_dense_layers = hparams['HP_NUM_DENSE_UNITS'],\n",
    "                                        increase=hparams['HP_INCREASE_UNITS_PER_LSTM_LAYER']),\n",
    "        \n",
    "        \"BidirectionalLSTM\": BidirectionalLSTM(num_hidden_units=hparams['HP_NUM_HIDDEN_UNITS'],\n",
    "                                             num_bidirectional_layers=hparams['HP_NUM_LSTM_LAYERS'],\n",
    "                                             num_dense_units = hparams['HP_NUM_DENSE_LAYERS'],\n",
    "                                             num_dense_layers = hparams['HP_NUM_DENSE_UNITS'],\n",
    "                                             increase=hparams['HP_INCREASE_UNITS_PER_LSTM_LAYER'])\n",
    "    }\n",
    "\n",
    "    return models.get(hparams['HP_MODEL_ARCHITECTURE'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vDinxqmPjcRT"
   },
   "outputs": [],
   "source": [
    "def run(hparams, logdir,savedir,checkpointdir,metrics):\n",
    "    \"\"\"\n",
    "    builds, compiles, trains and evaluates a model with certain architectual hyperparameters\n",
    "\n",
    "    Args:\n",
    "        hparams: selected hyperparameters\n",
    "        logdir: directory for logs\n",
    "        savedir: directors for saving the model\n",
    "        checkpointdir: direcotry for model checkpoints\n",
    "        metrics: a list of metrics we want to track\n",
    "\n",
    "    Returns:\n",
    "        accuracy of trained model evaluated on test data set\n",
    "    \"\"\"\n",
    "    model = build_model(hparams)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "\n",
    "\n",
    "    model.fit(train,\n",
    "              batch_size=64,\n",
    "              epochs=1,\n",
    "              validation_data=val,\n",
    "              verbose=0, # no output during training\n",
    "              callbacks=[tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "                        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "                        tf.keras.callbacks.ModelCheckpoint(filepath= os.path.join(checkpointdir, \"ckpt_{epoch}\") ,monitor='val_loss',save_weights_only=True), # save checkpoints when val loss goes down\n",
    "                        keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)], # early stopping in the case that loss doesnt go down for 3 epochs\n",
    "              ) \n",
    "    results = model.evaluate(test_features, test_labels)\n",
    "    model.save(savedir)\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(hparams_dict, logdir):\n",
    "    session_num = 0\n",
    "    for num_lstm_layers in hparams_dict['HP_NUM_LSTM_LAYERS'].domain.values:\n",
    "        for num_hidden_units in hparams_dict['HP_NUM_HIDDEN_UNITS'].domain.values:\n",
    "            for num_dense_layers in hparams_dict['HP_NUM_DENSE_LAYERS'].domain.values:\n",
    "                for num_dense_units in hparams_dict['HP_NUM_DENSE_UNITS'].domain.values:\n",
    "                    for increase in hparams_dict['HP_INCREASE_UNITS_PER_LSTM_LAYER'].domain.values:\n",
    "                        for model_architecture in hparams_dict['HP_MODEL_ARCHITECTURE'].domain.values:\n",
    "                            hparams = {\n",
    "                                'HP_MODEL_ARCHITECTURE': model_architecture,\n",
    "                                'HP_NUM_LSTM_LAYERS': num_lstm_layers,\n",
    "                                'HP_NUM_HIDDEN_UNITS': num_hidden_units,\n",
    "                                'HP_NUM_DENSE_LAYERS': num_dense_layers,\n",
    "                                'HP_NUM_DENSE_UNITS': num_dense_units,\n",
    "                                'HP_INCREASE_UNITS_PER_LSTM_LAYER': increase\n",
    "                            }\n",
    "                            run_name = \"run-%d\" % session_num\n",
    "                            #print('--- Starting trial: %s' % run_name)\n",
    "                            #print({h.name: hparams[h] for h in hparams})\n",
    "                            results = run(logdir=logdir+'hparam_tuning/' + run_name, \n",
    "                                          hparams=hparams, \n",
    "                                          savedir=logdir+'models/'+run_name, \n",
    "                                          checkpointdir=logdir+'checkpoints'+run_name,\n",
    "                                          metrics=metrics)\n",
    "                            session_num += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search 1 \n",
    "Plain MultiLayerLSTM and BidirectionalLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HParam(name='model_architecture', domain=Discrete(['BidirectionalLSTM', 'MultiLayerLSTM']), display_name=None, description=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HP_MODEL_ARCHITECTURE = hp.HParam('model_architecture', hp.Discrete(['MultiLayerLSTM', 'BidirectionalLSTM'])) # set model architecture as hyperparameter\n",
    "HP_NUM_LSTM_LAYERS = hp.HParam('num_lstm_layers', hp.Discrete([1, 2, 4])) # try out 1, 2 or 4 layers for architecture\n",
    "HP_NUM_HIDDEN_UNITS = hp.HParam('num_hidden_units', hp.Discrete([32, 64, 128, 256])) # try out different hidden_units\n",
    "HP_NUM_DENSE_UNITS = hp.HParam('num_dense_units', hp.Discrete([0])) # try out different number of units for dense layer\n",
    "HP_NUM_DENSE_LAYERS = hp.HParam('num_dense_layers', hp.Discrete([0])) # try out different number of dense layers\n",
    "HP_INCREASE_UNITS_PER_LSTM_LAYER = hp.HParam('increase_units_per_lstm_layer', hp.Discrete([0])) # increase number of units per lstm layer\n",
    "\n",
    "hparams_dict_1 = {\n",
    "    'HP_MODEL_ARCHITECTURE': HP_MODEL_ARCHITECTURE,\n",
    "    'HP_NUM_LSTM_LAYERS': HP_NUM_LSTM_LAYERS,\n",
    "    'HP_NUM_HIDDEN_UNITS': HP_NUM_HIDDEN_UNITS,\n",
    "    'HP_NUM_DENSE_UNITS': HP_NUM_DENSE_UNITS,\n",
    "    'HP_NUM_DENSE_LAYERS': HP_NUM_DENSE_LAYERS,\n",
    "    'HP_INCREASE_UNITS_PER_LSTM_LAYER': HP_INCREASE_UNITS_PER_LSTM_LAYER\n",
    "}\n",
    "\n",
    "search(logdir='logs1-1/', hparams_dict=hparams_dict_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search 2\n",
    "plain MultiLayerLSTM and BidirectionalLSTM but with increasing hidden units per lstm layer, every lstm layer get twice more hidden units than layer before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_MODEL_ARCHITECTURE = hp.HParam('model_architecture', hp.Discrete(['MultiLayerLSTM', 'BidirectionalLSTM'])) # set model architecture as hyperparameter\n",
    "HP_NUM_LSTM_LAYERS = hp.HParam('num_lstm_layers', hp.Discrete([1, 2, 4])) # try out 1, 2 or 4 layers for architecture\n",
    "HP_NUM_HIDDEN_UNITS = hp.HParam('num_hidden_units', hp.Discrete([32, 64, 128, 256])) # try out different hidden_units\n",
    "HP_NUM_DENSE_UNITS = hp.HParam('num_dense_units', hp.Discrete([0])) # try out different number of units for dense layer\n",
    "HP_NUM_DENSE_LAYERS = hp.HParam('num_dense_layers', hp.Discrete([0])) # try out different number of dense layers\n",
    "HP_INCREASE_UNITS_PER_LSTM_LAYER = hp.HParam('increase_units_per_lstm_layer', hp.Discrete([1])) # increase number of units per lstm layer\n",
    "\n",
    "hparams_dict_2 = {\n",
    "    'HP_MODEL_ARCHITECTURE': HP_MODEL_ARCHITECTURE,\n",
    "    'HP_NUM_LSTM_LAYERS': HP_NUM_LSTM_LAYERS,\n",
    "    'HP_NUM_HIDDEN_UNITS': HP_NUM_HIDDEN_UNITS,\n",
    "    'HP_NUM_DENSE_UNITS': HP_NUM_DENSE_UNITS,\n",
    "    'HP_NUM_DENSE_LAYERS': HP_NUM_DENSE_LAYERS,\n",
    "    'HP_INCREASE_UNITS_PER_LSTM_LAYER': HP_INCREASE_UNITS_PER_LSTM_LAYER\n",
    "}\n",
    "\n",
    "search(logdir='logs1-2/', hparams_dict=hparams_dict_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_MODEL_ARCHITECTURE = hp.HParam('model_architecture', hp.Discrete(['MultiLayerLSTM', 'BidirectionalLSTM'])) # set model architecture as hyperparameter\n",
    "HP_NUM_LSTM_LAYERS = hp.HParam('num_lstm_layers', hp.Discrete([1, 2, 4])) # try out 1, 2 or 4 layers for architecture\n",
    "HP_NUM_HIDDEN_UNITS = hp.HParam('num_hidden_units', hp.Discrete([32, 64, 128, 256])) # try out different hidden_units\n",
    "HP_NUM_DENSE_UNITS = hp.HParam('num_dense_units', hp.Discrete([128, 256])) # try out different number of units for dense layer\n",
    "HP_NUM_DENSE_LAYERS = hp.HParam('num_dense_layers', hp.Discrete([1,2,4])) # try out different number of dense layers\n",
    "HP_INCREASE_UNITS_PER_LSTM_LAYER = hp.HParam('increase_units_per_lstm_layer', hp.Discrete([0])) # increase number of units per lstm layer\n",
    "\n",
    "hparams_dict_3 = {\n",
    "    'HP_MODEL_ARCHITECTURE': HP_MODEL_ARCHITECTURE,\n",
    "    'HP_NUM_LSTM_LAYERS': HP_NUM_LSTM_LAYERS,\n",
    "    'HP_NUM_HIDDEN_UNITS': HP_NUM_HIDDEN_UNITS,\n",
    "    'HP_NUM_DENSE_UNITS': HP_NUM_DENSE_UNITS,\n",
    "    'HP_NUM_DENSE_LAYERS': HP_NUM_DENSE_LAYERS,\n",
    "    'HP_INCREASE_UNITS_PER_LSTM_LAYER': HP_INCREASE_UNITS_PER_LSTM_LAYER\n",
    "}\n",
    "\n",
    "search(logdir='logs1-2/', hparams_dict=hparams_dict_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "IFD-TSa9l6Tc",
    "9qo8QSn3q7tD",
    "JPmB8Wh1na2r",
    "jBbZmkDYj9xD",
    "j948o_LdwExJ",
    "i255ym_VodSF"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3449bbb043929c6f13b514689ff91c66257e0787e2d8bb0eba8270d3f40eacf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
