{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mePBKiuhLwI"
      },
      "source": [
        "#Imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Fg6CWtte8EP"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mylibs'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/leonackermann/Desktop/EEG-Artifact-Detection/hyperparams_optimization/Architecture Optimization/Hparameter_tuning_architecture_CNN.ipynb Cell 2\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonackermann/Desktop/EEG-Artifact-Detection/hyperparams_optimization/Architecture%20Optimization/Hparameter_tuning_architecture_CNN.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonackermann/Desktop/EEG-Artifact-Detection/hyperparams_optimization/Architecture%20Optimization/Hparameter_tuning_architecture_CNN.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leonackermann/Desktop/EEG-Artifact-Detection/hyperparams_optimization/Architecture%20Optimization/Hparameter_tuning_architecture_CNN.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmylibs\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mylibs'"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('./')\n",
        "from mylibs import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn70Oc6QfDv6"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1iggRVMfD_T"
      },
      "outputs": [],
      "source": [
        "from data.data import Data\n",
        "handler = Data()\n",
        "data = handler.load('../artifacts_5s_128hz.pkl')\n",
        "train_split, val_split, test_split = handler.split(data)\n",
        "\n",
        "# to-do: modify for CNN-transformer\n",
        "train = handler.prepare_data(train_split, balance=True, dataset=True)\n",
        "val = handler.prepare_data(val_split, dataset=True)\n",
        "test_features, test_labels = handler.prepare_data(test_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AIroNYSfIkx"
      },
      "source": [
        "# Setting up the Hparameter search grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uek2AkZOfGAZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "from architectures import CNN_w_attention\n",
        "\n",
        "# Define the hyperparameters you want to tune\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([320, 640]))\n",
        "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2,3,4,5]))\n",
        "HP_NUM_HEADS = hp.HParam('num_heads', hp.Discrete([4,8]))\n",
        "HP_NUM_CONVLAYERS = hp.HParam('num_convlayers', hp.Discrete([1,2,3,4,5]))\n",
        "\n",
        "# Define a function to build your model\n",
        "\n",
        "def create_model(hparams):\n",
        "\n",
        "    model = TestModel(hparams[HP_NUM_UNITS], hparams[HP_NUM_LAYERS], hparams[HP_NUM_HEADS], hparams[HP_NUM_CONVLAYERS])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define a function to run a single experiment\n",
        "\n",
        "def run_experiment(hparams, epochs, logdir, savedir, checkpointdir):\n",
        "    \n",
        "     # Create the model using the hyperparameters\n",
        "    model = create_model(hparams)\n",
        "\n",
        "\n",
        "   \n",
        "    # Compile the model\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_dataset, \n",
        "              epochs=epochs, \n",
        "              validation_data = val_dataset,\n",
        "              callbacks=[tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
        "                        hp.KerasCallback(logdir, hparams),  # log hparams\n",
        "                        tf.keras.callbacks.ModelCheckpoint(filepath= os.path.join(checkpointdir, \"ckpt_{epoch}\") ,monitor='val_loss',save_weights_only=True), # save checkpoints when val loss goes down\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)], # early stopping in the case that loss doesnt go down for 3 epochs\n",
        "              ) \n",
        "\n",
        "    \n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "    # Save model parameters\n",
        "    model.save(savedir)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xt0X25afJJ8"
      },
      "source": [
        "# Searching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN0BL7f_fIL9"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameter search space\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "session_num = 0\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "    for num_layers in HP_NUM_LAYERS.domain.values:\n",
        "       for num_heads in HP_NUM_HEADS.domain.values:\n",
        "         for num_convlayers in HP_NUM_CONVLAYERS.domain.values:\n",
        "                hparams = {\n",
        "                    HP_NUM_UNITS: num_units,\n",
        "                    HP_NUM_LAYERS: num_layers,\n",
        "                    HP_NUM_HEADS: num_heads,\n",
        "                    HP_NUM_CONVLAYERS: num_convlayers\n",
        "                }\n",
        "                run_name = \"run-%d\" % session_num\n",
        "                print('--- Starting trial: %s' % run_name)\n",
        "                print({h.name: hparams[h] for h in hparams})\n",
        "\n",
        "                # Run a single experiment\n",
        "                accuracy = run_experiment(\n",
        "                    hparams=hparams,\n",
        "                    epochs = 20,\n",
        "                    logdir='logs/hparam_tuning/' + run_name, \n",
        "                    savedir='logs/models/'+run_name, \n",
        "                    checkpointdir='logs/checkpoints'+run_name)\n",
        "                session_num += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
