{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "5mePBKiuhLwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fg6CWtte8EP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "from mylibs import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "cn70Oc6QfDv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data.data import Data\n",
        "handler = Data()\n",
        "data = handler.load('../artifacts_5s_128hz.pkl')\n",
        "train_split, val_split, test_split = handler.split(data)\n",
        "\n",
        "# to-do: modify for CNN-transformer\n",
        "train = handler.prepare_data(train_split, balance=True, dataset=True)\n",
        "val = handler.prepare_data(val_split, dataset=True)\n",
        "test_features, test_labels = handler.prepare_data(test_split)"
      ],
      "metadata": {
        "id": "g1iggRVMfD_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Hparameter search grid"
      ],
      "metadata": {
        "id": "0AIroNYSfIkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "\n",
        "from architectures import \n",
        "\n",
        "# Define the hyperparameters you want to tune\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([320, 640]))\n",
        "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2,3,4,5]))\n",
        "HP_NUM_HEADS = hp.HParam('num_heads', hp.Discrete([4,8]))\n",
        "HP_NUM_CONVLAYERS = hp.HParam('num_convlayers', hp.Discrete([1,2,3,4,5]))\n",
        "\n",
        "# Define a function to build your model\n",
        "\n",
        "def create_model(hparams):\n",
        "\n",
        "    model = TestModel(hparams[HP_NUM_UNITS], hparams[HP_NUM_LAYERS], hparams[HP_NUM_HEADS], hparams[HP_NUM_CONVLAYERS])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define a function to run a single experiment\n",
        "\n",
        "def run_experiment(hparams, epochs, logdir, savedir, checkpointdir):\n",
        "    \n",
        "     # Create the model using the hyperparameters\n",
        "    model = create_model(hparams)\n",
        "\n",
        "\n",
        "   \n",
        "    # Compile the model\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
        "              optimizer=tf.keras.optimizers.Adam(), \n",
        "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_dataset, \n",
        "              epochs=epochs, \n",
        "              validation_data = val_dataset,\n",
        "              callbacks=[tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
        "                        hp.KerasCallback(logdir, hparams),  # log hparams\n",
        "                        tf.keras.callbacks.ModelCheckpoint(filepath= os.path.join(checkpointdir, \"ckpt_{epoch}\") ,monitor='val_loss',save_weights_only=True), # save checkpoints when val loss goes down\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)], # early stopping in the case that loss doesnt go down for 3 epochs\n",
        "              ) \n",
        "\n",
        "    \n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "    # Save model parameters\n",
        "    model.save(savedir)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "uek2AkZOfGAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Searching\n"
      ],
      "metadata": {
        "id": "2xt0X25afJJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter search space\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "session_num = 0\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "    for num_layers in HP_NUM_LAYERS.domain.values:\n",
        "       for num_heads in HP_NUM_HEADS.domain.values:\n",
        "         for num_convlayers in HP_NUM_CONVLAYERS.domain.values:\n",
        "                hparams = {\n",
        "                    HP_NUM_UNITS: num_units,\n",
        "                    HP_NUM_LAYERS: num_layers,\n",
        "                    HP_NUM_HEADS: num_heads,\n",
        "                    HP_NUM_CONVLAYERS: num_convlayers\n",
        "                }\n",
        "                run_name = \"run-%d\" % session_num\n",
        "                print('--- Starting trial: %s' % run_name)\n",
        "                print({h.name: hparams[h] for h in hparams})\n",
        "\n",
        "                # Run a single experiment\n",
        "                accuracy = run_experiment(\n",
        "                    hparams=hparams,\n",
        "                    epochs = 20,\n",
        "                    logdir='logs/hparam_tuning/' + run_name, \n",
        "                    savedir='logs/models/'+run_name, \n",
        "                    checkpointdir='logs/checkpoints'+run_name)\n",
        "                session_num += 1"
      ],
      "metadata": {
        "id": "BN0BL7f_fIL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}